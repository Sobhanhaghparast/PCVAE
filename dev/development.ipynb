{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "def rotate_point_cloud(points):\n",
    "    \"\"\"\n",
    "    Randomly rotates the point cloud around the Z-axis for 2D, or around a random axis for 3D.\n",
    "\n",
    "    Args:\n",
    "        points (torch.Tensor): Input point cloud of shape (N, 2) or (N, 3).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Rotated point cloud of shape (N, 2) or (N, 3).\n",
    "    \"\"\"\n",
    "    if points.shape[1] == 2:\n",
    "        angle = torch.rand(1).item() * 2 * torch.pi\n",
    "        angle = torch.tensor(angle)\n",
    "        rotation_matrix = torch.tensor([\n",
    "            [torch.cos(angle), -torch.sin(angle)],\n",
    "            [torch.sin(angle), torch.cos(angle)]\n",
    "        ])\n",
    "        return points @ rotation_matrix.T\n",
    "    elif points.shape[1] == 3:\n",
    "        # Rotation around a random axis in 3D\n",
    "        angle = torch.rand(1).item() * 2 * torch.pi\n",
    "        angle = torch.tensor(angle)\n",
    "        axis = torch.rand(3) - 0.5\n",
    "        axis = axis / axis.norm()\n",
    "        rotation_matrix = torch.eye(3)\n",
    "        rotation_matrix = rotation_matrix + torch.sin(angle) * torch.cross(torch.eye(3), axis) + (1 - torch.cos(angle)) * (axis.unsqueeze(1) @ axis.unsqueeze(0))\n",
    "        return points @ rotation_matrix.T\n",
    "    else:\n",
    "        raise ValueError(\"Points should have shape (N, 2) or (N, 3)\")\n",
    "\n",
    "def translate_point_cloud(points):\n",
    "    \"\"\"\n",
    "    Randomly translates the point cloud.\n",
    "\n",
    "    Args:\n",
    "        points (torch.Tensor): Input point cloud of shape (N, 2) or (N, 3).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Translated point cloud of shape (N, 2) or (N, 3).\n",
    "    \"\"\"\n",
    "    translation = torch.rand(1, points.shape[1]) - 0.5\n",
    "    return points + translation\n",
    "\n",
    "\n",
    "\n",
    "def pad_point_cloud(point_cloud, uncertainty, max_points):\n",
    "    \"\"\"\n",
    "    Pads the point cloud to a fixed number of points.\n",
    "\n",
    "    Args:\n",
    "        point_cloud (torch.Tensor): Input point cloud of shape (N, 2).\n",
    "        uncertainty (torch.Tensor): Uncertainty values of shape (N,).\n",
    "        max_points (int): Number of points to pad to.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Padded point cloud of shape (max_points, 2), padded uncertainty, and the number of original points.\n",
    "    \"\"\"\n",
    "    num_points = point_cloud.shape[0]\n",
    "    if num_points < max_points:\n",
    "        padded_points = torch.zeros((max_points, point_cloud.shape[1]), dtype=torch.float32)\n",
    "        padded_uncertainty = torch.zeros(max_points, dtype=torch.float32)\n",
    "        padded_points[:num_points, :] = point_cloud\n",
    "        padded_uncertainty[:num_points] = uncertainty\n",
    "    else:\n",
    "        padded_points = point_cloud[:max_points, :]\n",
    "        padded_uncertainty = uncertainty[:max_points]\n",
    "    return padded_points, padded_uncertainty, num_points\n",
    "\n",
    "class PointCloudDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Point Cloud Dataset.\n",
    "\n",
    "    Args:\n",
    "        csv_dir (str): Directory containing CSV files.\n",
    "        num_files (int): Number of CSV files.\n",
    "        max_points (int): Maximum number of points in the point cloud.\n",
    "        augment (bool): Whether to apply data augmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_dir, num_files, max_points, augment=False):\n",
    "        self.csv_dir = csv_dir\n",
    "        self.num_files = num_files\n",
    "        self.max_points = max_points\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_files\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.csv_dir, f\"{idx + 1}.csv\")\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Extract x, y coordinates and uncertainty\n",
    "        x = torch.tensor(data.iloc[:, 0].values, dtype=torch.float32)\n",
    "        y = torch.tensor(data.iloc[:, 1].values, dtype=torch.float32)\n",
    "        uncertainty = torch.tensor(data.iloc[:, 2].values, dtype=torch.float32)\n",
    "        points = torch.stack((x, y), dim=1)\n",
    "\n",
    "        if self.augment:\n",
    "            points = rotate_point_cloud(points)\n",
    "            points = translate_point_cloud(points)\n",
    "\n",
    "        # Pad point cloud and uncertainty\n",
    "        padded_points, padded_uncertainty, num_points = pad_point_cloud(points, uncertainty, self.max_points)\n",
    "\n",
    "        # Extract label (fourth column)\n",
    "        label = torch.tensor(data.iloc[0, 3], dtype=torch.float32)\n",
    "\n",
    "        # Create mask\n",
    "        mask = torch.tensor([1] * num_points + [0] * (self.max_points - num_points), dtype=torch.float32)\n",
    "\n",
    "        return padded_points, padded_uncertainty, label, mask\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for DataLoader.\n",
    "\n",
    "    Args:\n",
    "        batch (list): List of samples.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Batch of points, uncertainties, labels, and masks.\n",
    "    \"\"\"\n",
    "    points = torch.stack([item[0] for item in batch])\n",
    "    uncertainties = torch.stack([item[1] for item in batch])\n",
    "    labels = torch.stack([item[2] for item in batch])\n",
    "    masks = torch.stack([item[3] for item in batch])\n",
    "    return points, uncertainties, labels, masks\n",
    "\n",
    "\n",
    "def create_dataloader(csv_dir, num_files, max_points, batch_size, augment=False):\n",
    "    \"\"\"\n",
    "    Creates a DataLoader for the Point Cloud Dataset.\n",
    "\n",
    "    Args:\n",
    "        csv_dir (str): Directory containing CSV files.\n",
    "        num_files (int): Number of CSV files.\n",
    "        max_points (int): Maximum number of points in the point cloud.\n",
    "        batch_size (int): Batch size.\n",
    "        augment (bool): Whether to apply data augmentation.\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: DataLoader for the dataset.\n",
    "    \"\"\"\n",
    "    dataset = PointCloudDataset(csv_dir, num_files, max_points, augment=augment)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# Example usage\n",
    "csv_dir = 'datapointvae/'\n",
    "num_files = 6000\n",
    "max_points = 1024\n",
    "batch_size = 32\n",
    "augment = True  # Enable data augmentation\n",
    "\n",
    "dataloader = create_dataloader(csv_dir, num_files, max_points, batch_size, augment=augment)\n",
    "\n",
    "# Fetch a batch of data\n",
    "points, labels, uncertainties, masks = next(iter(dataloader))\n",
    "\n",
    "# Visualize a data point\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_point_cloud(points, mask):\n",
    "    \"\"\"\n",
    "    Visualizes a point cloud with a black background and red points.\n",
    "    \n",
    "    Args:\n",
    "        points (torch.Tensor): Point cloud of shape (N, 2).\n",
    "        mask (torch.Tensor): Mask indicating valid points.\n",
    "    \"\"\"\n",
    "    # Filter out padding points\n",
    "    filtered_points = points[mask]\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, facecolor='black')\n",
    "    ax.set_xlim(-128, 128)\n",
    "    ax.set_ylim(-128, 128)\n",
    "    # background color black\n",
    "    ax.set_facecolor('black')\n",
    "    ax.scatter(filtered_points[:, 0], filtered_points[:, 1], s=50, c='red', marker='o')\n",
    "\n",
    "# Fetch a batch of data from the DataLoader\n",
    "points, labels,uncertainties, masks = next(iter(dataloader))\n",
    "\n",
    "# Select a data point for visualization\n",
    "data_point = points[0].numpy()\n",
    "mask = masks[0].numpy().astype(bool)\n",
    "\n",
    "# Visualize the point cloud\n",
    "visualize_point_cloud(data_point, mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "class TNet(nn.Module):\n",
    "    \"\"\"\n",
    "    T-Net module for learning a transformation matrix to align input point clouds.\n",
    "    \n",
    "    Args:\n",
    "        k (int): The dimension of the input point cloud.\n",
    "    \"\"\"\n",
    "    def __init__(self, k):\n",
    "        super(TNet, self).__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k)\n",
    "        self.iden = torch.eye(k).flatten().unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        iden = self.iden.repeat(batchsize, 1).to(x.device)\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    PointNet encoder for encoding point clouds into a latent space representation.\n",
    "    \n",
    "    Args:\n",
    "        latent_dim (int): The dimension of the latent space.\n",
    "        input_dim (int): The dimension of the input point cloud.\n",
    "        use_tnet (bool): Whether to use the T-Net module.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, input_dim=3, use_tnet=True):\n",
    "        super(PointNetEncoder, self).__init__()\n",
    "        self.use_tnet = use_tnet\n",
    "        self.input_dim = input_dim\n",
    "        if self.use_tnet:\n",
    "            self.tnet = TNet(k=input_dim)\n",
    "        self.conv1 = nn.Conv1d(input_dim, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3_mean = nn.Linear(256, latent_dim)\n",
    "        self.fc3_logvar = nn.Linear(256, latent_dim)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        if self.use_tnet:\n",
    "            trans = self.tnet(x)\n",
    "            x = torch.bmm(trans, x)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = x * mask.float()\n",
    "\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mean = self.fc3_mean(x)\n",
    "        logvar = self.fc3_logvar(x)\n",
    "        return mean, logvar\n",
    "\n",
    "class PointNetDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    PointNet decoder for reconstructing point clouds from the latent space representation.\n",
    "    \n",
    "    Args:\n",
    "        latent_dim (int): The dimension of the latent space.\n",
    "        num_points (int): The number of points in the output point cloud.\n",
    "        output_dim (int): The dimension of the output point cloud.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, num_points, output_dim=3):\n",
    "        super(PointNetDecoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, num_points * output_dim)\n",
    "        self.num_points = num_points\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def forward(self, z, mask):\n",
    "        x = F.relu(self.fc1(z))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = x.view(-1, self.output_dim, self.num_points)\n",
    "        x = x * mask.unsqueeze(1).float()\n",
    "        return x\n",
    "\n",
    "class PointNetVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    PointNet Variational Autoencoder for point clouds.\n",
    "    \n",
    "    Args:\n",
    "        latent_dim (int): The dimension of the latent space.\n",
    "        num_points (int): The number of points in the output point cloud.\n",
    "        input_dim (int): The dimension of the input point cloud.\n",
    "        output_dim (int): The dimension of the output point cloud.\n",
    "        use_tnet (bool): Whether to use the T-Net module.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, num_points, input_dim=3, output_dim=3, use_tnet=True):\n",
    "        super(PointNetVAE, self).__init__()\n",
    "        self.encoder = PointNetEncoder(latent_dim, input_dim, use_tnet)\n",
    "        self.decoder = PointNetDecoder(latent_dim, num_points, output_dim)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        mean, logvar = self.encoder(x, mask)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        recon_x = self.decoder(z, mask)\n",
    "        return recon_x, mean, logvar\n",
    "\n",
    "def loss_function(recon_x, x, mean, logvar, mask, loss_type='mse'):\n",
    "    \"\"\"\n",
    "    Loss function for the VAE, including reconstruction loss and KL divergence.\n",
    "    \n",
    "    Args:\n",
    "        recon_x (torch.Tensor): Reconstructed point cloud.\n",
    "        x (torch.Tensor): Original point cloud.\n",
    "        mean (torch.Tensor): Mean of the latent space distribution.\n",
    "        logvar (torch.Tensor): Log variance of the latent space distribution.\n",
    "        mask (torch.Tensor): Mask indicating valid points.\n",
    "        loss_type (str): Type of reconstruction loss ('mse', 'chamfer', 'emd').\n",
    "\n",
    "    Returns:\n",
    "        tuple: Reconstruction loss and KL divergence.\n",
    "    \"\"\"\n",
    "    recon_x = recon_x.permute(0, 2, 1)\n",
    "    x = x.permute(0, 2, 1)\n",
    "    mask = mask.unsqueeze(2).float()\n",
    "    \n",
    "    if loss_type == 'mse':\n",
    "        recon_loss = F.mse_loss(recon_x * mask, x * mask, reduction='sum')\n",
    "    elif loss_type == 'chamfer':\n",
    "        recon_loss = chamfer_distance(recon_x * mask, x * mask)[0]\n",
    "    elif loss_type == 'emd':\n",
    "        # Note: PyTorch3D does not have a direct EMD implementation, consider implementing your own or using an available library.\n",
    "        raise NotImplementedError(\"EMD loss is not implemented.\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported loss type: {loss_type}\")\n",
    "\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "    return recon_loss, kld_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"\n",
    "    Trainer class for training and validating the PointNetVAE model.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): The PointNetVAE model.\n",
    "        train_loader (DataLoader): DataLoader for the training data.\n",
    "        val_loader (DataLoader): DataLoader for the validation data.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer for the model.\n",
    "        criterion (function): Loss function for the model.\n",
    "        device (str): Device to run the model on ('cpu' or 'cuda').\n",
    "        log_dir (str): Directory to save TensorBoard logs.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, train_loader, val_loader, optimizer, criterion, device='cuda', log_dir='./logs'):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "        self.model.to(self.device)\n",
    "        self.step = 0\n",
    "    def train(self, epochs):\n",
    "        \"\"\"\n",
    "        Trains the model for a given number of epochs.\n",
    "\n",
    "        Args:\n",
    "            epochs (int): Number of epochs to train the model for.\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            train_recon_loss = 0\n",
    "            train_kld_loss = 0\n",
    "            \n",
    "            for batch in self.train_loader:\n",
    "                self.step += 1\n",
    "                points, uncertainties, labels, masks = batch\n",
    "                points, masks = points.to(self.device), masks.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                recon_points, mean, logvar = self.model(points,masks)\n",
    "                recon_loss, kld_loss = self.criterion(recon_points, points, mean, logvar, masks)\n",
    "                loss = recon_loss + kld_loss\n",
    "                # step logging\n",
    "                self.writer.add_scalar('Loss/recon_loss_step', recon_loss.item(), self.step)\n",
    "                self.writer.add_scalar('Loss/kld_loss_step', kld_loss.item(), self.step)\n",
    "                self.writer.add_scalar('Loss/total_loss_step', loss.item(), self.step)\n",
    "                \n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                train_recon_loss += recon_loss.item()\n",
    "                train_kld_loss += kld_loss.item()\n",
    "\n",
    "            train_recon_loss /= len(self.train_loader)\n",
    "            train_kld_loss /= len(self.train_loader)\n",
    "            self.writer.add_scalar('Loss/train_recon', train_recon_loss, epoch)\n",
    "            self.writer.add_scalar('Loss/train_kld', train_kld_loss, epoch)\n",
    "            self.writer.add_scalar('Loss/total_loss', train_recon_loss + train_kld_loss, epoch)\n",
    "            self._log_images(points, recon_points, masks, epoch, mode='train')\n",
    "\n",
    "            val_recon_loss, val_kld_loss = self.validate(epoch)\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], Train Recon Loss: {train_recon_loss:.4f}, Train KLD Loss: {train_kld_loss:.4f}, Val Recon Loss: {val_recon_loss:.4f}, Val KLD Loss: {val_kld_loss:.4f}\")\n",
    "\n",
    "    def validate(self, epoch):\n",
    "        \"\"\"\n",
    "        Validates the model on the validation set.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): Current epoch number.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Validation reconstruction loss and KL divergence.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_recon_loss = 0\n",
    "        val_kld_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_loader:\n",
    "                points, uncertainties, labels, masks = batch\n",
    "                points, masks = points.to(self.device), masks.to(self.device)\n",
    "\n",
    "                recon_points, mean, logvar = self.model(points, masks.sum(dim=1).long(), masks)\n",
    "                recon_loss, kld_loss = self.criterion(recon_points, points, mean, logvar, masks)\n",
    "                val_recon_loss += recon_loss.item()\n",
    "                val_kld_loss += kld_loss.item()\n",
    "\n",
    "            val_recon_loss /= len(self.val_loader)\n",
    "            val_kld_loss /= len(self.val_loader)\n",
    "            self.writer.add_scalar('Loss/val_recon', val_recon_loss, epoch)\n",
    "            self.writer.add_scalar('Loss/val_kld', val_kld_loss, epoch)\n",
    "            self.writer.add_scalar('Loss/val_total', val_recon_loss + val_kld_loss, epoch)\n",
    "            self._log_images(points, recon_points, masks, epoch, mode='val')\n",
    "\n",
    "        return val_recon_loss, val_kld_loss\n",
    "\n",
    "    def _log_images(self, original, reconstructed, mask, epoch, mode):\n",
    "        \"\"\"\n",
    "        Logs the original and reconstructed point clouds to TensorBoard.\n",
    "\n",
    "        Args:\n",
    "            original (torch.Tensor): Original point clouds.\n",
    "            reconstructed (torch.Tensor): Reconstructed point clouds.\n",
    "            mask (torch.Tensor): Mask indicating valid points.\n",
    "            epoch (int): Current epoch number.\n",
    "            mode (str): Mode of logging ('train' or 'val').\n",
    "        \"\"\"\n",
    "        original = original.cpu().detach()\n",
    "        reconstructed = reconstructed.cpu().detach()\n",
    "        mask = mask.cpu().detach()\n",
    "\n",
    "        for i in range(min(4, original.size(0))):\n",
    "            orig = original[i][mask[i].bool()]\n",
    "            recon = reconstructed[i][mask[i].bool()]\n",
    "            diff = (orig - recon).abs()\n",
    "\n",
    "            self.writer.add_figure(f'{mode}_original/point_cloud_{i}', self._plot_point_cloud(orig), epoch)\n",
    "            self.writer.add_figure(f'{mode}_reconstructed/point_cloud_{i}', self._plot_point_cloud(recon), epoch)\n",
    "            self.writer.add_figure(f'{mode}_difference/point_cloud_{i}', self._plot_point_cloud(diff), epoch)\n",
    "\n",
    "    @staticmethod\n",
    "\n",
    "    @staticmethod\n",
    "    def _plot_point_cloud(points):\n",
    "        \"\"\"\n",
    "        Plots the point cloud.\n",
    "\n",
    "        Args:\n",
    "            points (torch.Tensor): Point cloud to plot.\n",
    "\n",
    "        Returns:\n",
    "            matplotlib.figure.Figure: Figure of the plotted point cloud.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.scatter(points[:, 0], points[:, 1], c='red', s=50, marker='o')\n",
    "        ax.set_facecolor('black')\n",
    "        ax.set_xlim(-128, 128)\n",
    "        ax.set_ylim(-128, 128)\n",
    "        ax.axis('off')\n",
    "        return fig\n",
    "\n",
    "# Example usage\n",
    "csv_dir = 'datapointvae/'\n",
    "num_files = 6000\n",
    "max_points = 1024\n",
    "batch_size = 16\n",
    "latent_dim = 32\n",
    "augment = False  # Enable data augmentation\n",
    "use_tnet = False  # Enable T-Net\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = create_dataloader(csv_dir, num_files, max_points, batch_size, augment=augment)\n",
    "val_dataloader = create_dataloader(csv_dir, num_files, max_points, batch_size, augment=False)\n",
    "train_indices = list(range(int(len(train_dataloader) * 0.8)))\n",
    "val_indices = list(range(int(len(train_dataloader) * 0.8), len(train_dataloader)))\n",
    "train_loader = DataLoader(Subset(train_dataloader.dataset, train_indices), batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(Subset(val_dataloader.dataset, val_indices), batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = PointNetVAE(latent_dim, max_points, use_tnet=use_tnet)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 1], expected input[16, 1024, 2] to have 3 channels, but got 1024 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, train_loader, val_loader, optimizer, loss_function)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 47\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m points, masks \u001b[38;5;241m=\u001b[39m points\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), masks\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 47\u001b[0m recon_points, mean, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m recon_loss, kld_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(recon_points, points, mean, logvar, masks)\n\u001b[1;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m recon_loss \u001b[38;5;241m+\u001b[39m kld_loss\n",
      "File \u001b[0;32m/mnt/vol4t/miniconda/envs/mia-ssd/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/vol4t/miniconda/envs/mia-ssd/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[56], line 129\u001b[0m, in \u001b[0;36mPointNetVAE.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask):\n\u001b[0;32m--> 129\u001b[0m     mean, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mean, logvar)\n\u001b[1;32m    131\u001b[0m     recon_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z, mask)\n",
      "File \u001b[0;32m/mnt/vol4t/miniconda/envs/mia-ssd/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/vol4t/miniconda/envs/mia-ssd/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[56], line 67\u001b[0m, in \u001b[0;36mPointNetEncoder.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     64\u001b[0m     trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtnet(x)\n\u001b[1;32m     65\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(trans, x)\n\u001b[0;32m---> 67\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     68\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[1;32m     69\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))\n",
      "File \u001b[0;32m/mnt/vol4t/miniconda/envs/mia-ssd/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/vol4t/miniconda/envs/mia-ssd/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/vol4t/miniconda/envs/mia-ssd/lib/python3.11/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/vol4t/miniconda/envs/mia-ssd/lib/python3.11/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 1], expected input[16, 1024, 2] to have 3 channels, but got 1024 channels instead"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, train_loader, val_loader, optimizer, loss_function)\n",
    "trainer.train(epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
